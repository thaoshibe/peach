project_name: "YoChameleon"
entity: "thaoshibe-university-of-wisconsin-madison"

model_id: 'leloy/Anole-7b-v0.1-hf'
data_root: '/nobackup3/thao-data/data/mini-yochameleon-data'

json_file: # Remember to change this
  - '/nobackup3/thao-data/data/mini-yochameleon-data/train/SKS_NAME/json/recognition.json'
  - '/nobackup3/thao-data/data/mini-yochameleon-data/train/SKS_NAME/json/text_conversation.json'
  - '/nobackup3/thao-data/data/mini-yochameleon-data/train/SKS_NAME/json/1000.json'

sks_name: 'thao'
prefix_token: 16 # Remember to change this
exp_name: 'task_prefix' # Remember to change this
different_identifier: False
task_disjoin: False
self_prompting: True

seperate_tasks: False # This means, the model will be trained on all tasks (recognition, gen) with same tokens, or seperate

iteration: 1001 # remember to CHANGE THIS shibe; Currently it will use epochs for training
epoch: 16000 # remember to CHANGE THIS shibe; Currently it will use epochs for training
save_every: 200

batch_size: 4
savedir: './ckpt/'
# savedir: '/sensei-fs/users/thaon/ckpt-04112024/'
whole_model: False
tokenizer_max_length: 1500
eval_visualization: True

optimizer:
  type: 'AdamW'
  lr: 0.001
  betas: [0.9, 0.999]
  weight_decay: 1e-4
  eps: 1e-6
  grad_clip: -1 # only use if grad_clip >0

scheduler:
  # type: 'StepLR'
  type: 'No' # Currently only StepLR is implemented
  step_size: 10
  gamma: 0.05

special_tokens:
  START_OF_IMAGE_INDEX: 8197
  END_OF_IMAGE_INDEX: 8196
  END_OF_TURN: 8710
  PAD_INDEX: 1
  SKS_TOKEN: '<reserved16200>'
  LATENT_TOKEN_START: 16201

resume: 
  resume: No
  resume_iteration: 15
  savedir: './ckpt/'
  exp_name: '1000disjoin'

finetune:
  finetune: False
  finetune_iteration: 201 # remember to CHANGE THIS shibe
  finetune_epoch: 6 # remember to CHANGE THIS shibe
  save_every: 1
  optimizer:
    type: 'AdamW'
    lr: 0.00001
    betas: [0.9, 0.999]
    weight_decay: 1e-4
    eps: 1e-6
    grad_clip: -1 # only use if grad_clip >0
  scheduler:
    # type: 'StepLR'
    type: 'No' # Currently only StepLR is implemented
    step_size: 10
    gamma: 0.05

# --- EVAL CONFIG --- 
eval:
  clip_sim: False
  number_fake_images: 1
  recognition: False
  recognition_path_train: '/mnt/localssd/code/data/yochameleon-data/train'
  recognition_path_test: '/mnt/localssd/code/data/yochameleon-data/test'
  ############
  #
  # NOT YET IMPLEMETED
  #
  ##########
  vqa: True
  vqa_path_json: './baselines/yollava-visual-qa.json'

# --- TEST CONFIG --- 
test:
  prompt: "A photo of <reserved16200>."
  iteration: 200 # this will not affect the train code -- generated images are always with lastest checkpoints
  save_dir: './ckpt/generated_images/'
  batch_size: 16
  num_images: 100